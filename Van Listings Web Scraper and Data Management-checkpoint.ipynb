{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b4f7048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data from page 1\n",
      "Scraped data from page 2\n",
      "Scraped data from page 3\n",
      "Scraped data from page 4\n",
      "Scraped data from page 5\n",
      "Scraped data from page 6\n",
      "Scraped data from page 7\n",
      "Scraped data from page 8\n",
      "Scraped data from page 9\n",
      "Scraped data from page 10\n",
      "Scraped data from page 11\n",
      "Scraped data from page 12\n",
      "Scraped data from page 13\n",
      "Scraped data from page 14\n",
      "Scraped data from page 15\n",
      "Scraped data from page 16\n",
      "Scraped data from page 17\n",
      "Scraped data from page 18\n",
      "Scraped data from page 19\n",
      "Scraped data from page 20\n",
      "Scraped data from page 21\n",
      "Scraped data from page 22\n",
      "Scraped data from page 23\n",
      "Scraped data from page 24\n",
      "Scraped data from page 25\n",
      "Scraped data from page 26\n",
      "Scraped data from page 27\n",
      "Scraped data from page 28\n",
      "Scraped data from page 29\n",
      "Scraped data from page 30\n",
      "Scraped data from page 31\n",
      "Scraped data from page 32\n",
      "Scraped data from page 33\n",
      "Scraped data from page 34\n",
      "Scraped data from page 35\n",
      "Scraped data from page 36\n",
      "Scraped data from page 37\n",
      "Scraped data from page 38\n",
      "Scraped data from page 39\n",
      "Scraped data from page 40\n",
      "Data has been successfully scraped and saved to Google Sheets.\n",
      "Number of scraped vans: 720\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "# Set up Selenium Chrome driver\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode (without GUI)\n",
    "service = Service(\"path/to/chromedriver\")  # Replace with the actual path to chromedriver executable\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Define the URL pattern for the pages\n",
    "url_pattern = \"https://www.camplify.co.nz/s?seed=8031&page={}\"\n",
    "\n",
    "# Initialize an empty list to store the scraped data\n",
    "vans_data = []\n",
    "\n",
    "# Iterate over the pages\n",
    "for page_number in range(1, 41):  \n",
    "    # Construct the URL for the current page\n",
    "    url = url_pattern.format(page_number)\n",
    "    \n",
    "    # Load the web page\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for the page to load (adjust the waiting time as needed)\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    # Find all the van listings on the page\n",
    "    van_listings = driver.find_elements(By.CLASS_NAME, \"RvCard__Content\")\n",
    "    \n",
    "    # Iterate over each van listing and extract the required information\n",
    "    for van_listing in van_listings:\n",
    "        # Extract the van title\n",
    "        van_title = van_listing.find_element(By.CLASS_NAME, \"RvCard__Title\").text.strip()\n",
    "        \n",
    "        # Extract the description\n",
    "        description = van_listing.find_element(By.CLASS_NAME, \"RvCard__Description\").text.strip()\n",
    "        \n",
    "        # Extract the location\n",
    "        location = van_listing.find_element(By.CLASS_NAME, \"RvCard__LocationText\").text.strip()\n",
    "        \n",
    "        # Extract the star rating\n",
    "        star_rating = van_listing.find_element(By.CLASS_NAME, \"StarRatingWithCount__TotalReviews\").text.strip()\n",
    "        \n",
    "        # Extract the price\n",
    "        price = van_listing.find_element(By.CLASS_NAME, \"RvCard__PriceValue\").text.strip()\n",
    "        \n",
    "        # Append the extracted information to the vans_data list\n",
    "        vans_data.append([van_title, description, location, star_rating, price])\n",
    "    \n",
    "    print(\"Scraped data from page\", page_number)\n",
    "\n",
    "# Close the Selenium Chrome driver\n",
    "driver.quit()\n",
    "\n",
    "# Authenticate with Google Sheets API\n",
    "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(r\"C:\\Users\\USER\\.ipynb_checkpoints\\credentials.json.json\", scope)\n",
    "client = gspread.authorize(credentials)\n",
    "\n",
    "# Open the Google Sheets document\n",
    "spreadsheet = client.open(\"Van Listings\")\n",
    "\n",
    "# Select the first sheet in the document\n",
    "sheet = spreadsheet.get_worksheet(0)\n",
    "\n",
    "# Clear the existing content in the sheet\n",
    "sheet.clear()\n",
    "\n",
    "# Write the headers to the Google Sheets document\n",
    "headers = [\"Van Title\", \"Description\", \"Location\", \"Star Rating\", \"Price\"]\n",
    "sheet.update(\"A1:E1\", [headers])\n",
    "\n",
    "# Write the scraped data to the Google Sheets document\n",
    "sheet.update(\"A2:E{}\".format(len(vans_data) + 1), vans_data)\n",
    "\n",
    "print(\"Data has been successfully scraped and saved to Google Sheets.\")\n",
    "print(\"Number of scraped vans:\", len(vans_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d23bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
